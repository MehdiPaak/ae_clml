{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action failed <400/101: tasks.get_by_id/v1.0 (Invalid task id: id=d, company=6eff4d3f-42d3-473f-9d1f-7e3548af2b7f)> (task=d)\n",
      "Failed reloading task d\n",
      "Action failed <400/101: tasks.get_by_id/v1.0 (Invalid task id: id=d, company=6eff4d3f-42d3-473f-9d1f-7e3548af2b7f)> (task=d)\n",
      "Failed reloading task d\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Task ID \"d\" could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Preprocessing code here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      3\u001b[0m   dataset_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msample_nlst_local\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m   dataset_project\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmehdi_test_nlst/clml_dataset\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      5\u001b[0m   parent_datasets\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdff321121eb7463b8180e03e331c189d\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m   \u001b[39m#dataset_version=\"1.0\",\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m   \u001b[39m#output_uri=\"gs://bucket-name/folder\",\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m   description\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcsv added, small sample of nlst from local\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/clearml/lib/python3.10/site-packages/clearml/datasets/dataset.py:1200\u001b[0m, in \u001b[0;36mDataset.create\u001b[0;34m(cls, dataset_name, dataset_project, dataset_tags, parent_datasets, use_current_task, dataset_version, output_uri, description)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Session\u001b[39m.\u001b[39mcheck_min_api_server_version(\u001b[39m\"\u001b[39m\u001b[39m2.13\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1198\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDatasets are not supported with your current ClearML server version. Please update your server.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1200\u001b[0m parent_datasets \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget(dataset_id\u001b[39m=\u001b[39mp) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(p, Dataset) \u001b[39melse\u001b[39;00m p \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m (parent_datasets \u001b[39mor\u001b[39;00m [])]\n\u001b[1;32m   1201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mnot\u001b[39;00m p\u001b[39m.\u001b[39mis_final() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m parent_datasets):\n\u001b[1;32m   1202\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot inherit from a parent that was not finalized/closed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/clearml/lib/python3.10/site-packages/clearml/datasets/dataset.py:1200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Session\u001b[39m.\u001b[39mcheck_min_api_server_version(\u001b[39m\"\u001b[39m\u001b[39m2.13\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1198\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDatasets are not supported with your current ClearML server version. Please update your server.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1200\u001b[0m parent_datasets \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget(dataset_id\u001b[39m=\u001b[39;49mp) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(p, Dataset) \u001b[39melse\u001b[39;00m p \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m (parent_datasets \u001b[39mor\u001b[39;00m [])]\n\u001b[1;32m   1201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mnot\u001b[39;00m p\u001b[39m.\u001b[39mis_final() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m parent_datasets):\n\u001b[1;32m   1202\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot inherit from a parent that was not finalized/closed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/clearml/lib/python3.10/site-packages/clearml/datasets/dataset.py:1731\u001b[0m, in \u001b[0;36mDataset.get\u001b[0;34m(cls, dataset_id, dataset_project, dataset_name, dataset_tags, only_completed, only_published, include_archived, auto_create, writable_copy, dataset_version, alias, overridable, shallow_search, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     instance \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m   1728\u001b[0m         dataset_name\u001b[39m=\u001b[39mdataset_name, dataset_project\u001b[39m=\u001b[39mdataset_project, dataset_tags\u001b[39m=\u001b[39mdataset_tags\n\u001b[1;32m   1729\u001b[0m     )\n\u001b[1;32m   1730\u001b[0m     \u001b[39mreturn\u001b[39;00m finish_dataset_get(instance, instance\u001b[39m.\u001b[39m_id)\n\u001b[0;32m-> 1731\u001b[0m instance \u001b[39m=\u001b[39m get_instance(dataset_id)\n\u001b[1;32m   1732\u001b[0m \u001b[39m# Now we have the requested dataset, but if we want a mutable copy instead, we create a new dataset with the\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39m# current one as its parent. So one can add files to it and finalize as a new version.\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m \u001b[39mif\u001b[39;00m writable_copy:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/clearml/lib/python3.10/site-packages/clearml/datasets/dataset.py:1630\u001b[0m, in \u001b[0;36mDataset.get.<locals>.get_instance\u001b[0;34m(dataset_id_)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_instance\u001b[39m(dataset_id_):\n\u001b[0;32m-> 1630\u001b[0m     task \u001b[39m=\u001b[39m Task\u001b[39m.\u001b[39;49mget_task(task_id\u001b[39m=\u001b[39;49mdataset_id_)\n\u001b[1;32m   1631\u001b[0m     \u001b[39mif\u001b[39;00m task\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1632\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset id=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is in draft mode, delete and recreate it\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(task\u001b[39m.\u001b[39mid))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/clearml/lib/python3.10/site-packages/clearml/task.py:933\u001b[0m, in \u001b[0;36mTask.get_task\u001b[0;34m(cls, task_id, project_name, task_name, tags, allow_archived, task_filter)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    876\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_task\u001b[39m(\n\u001b[1;32m    877\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    884\u001b[0m ):\n\u001b[1;32m    885\u001b[0m     \u001b[39m# type: (...) -> TaskInstance\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    Get a Task by ID, or project name / task name combination.\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[39m    :rtype: Task\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__get_task(\n\u001b[1;32m    934\u001b[0m         task_id\u001b[39m=\u001b[39;49mtask_id, project_name\u001b[39m=\u001b[39;49mproject_name, task_name\u001b[39m=\u001b[39;49mtask_name, tags\u001b[39m=\u001b[39;49mtags,\n\u001b[1;32m    935\u001b[0m         include_archived\u001b[39m=\u001b[39;49mallow_archived, task_filter\u001b[39m=\u001b[39;49mtask_filter,\n\u001b[1;32m    936\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/clearml/lib/python3.10/site-packages/clearml/task.py:4136\u001b[0m, in \u001b[0;36mTask.__get_task\u001b[0;34m(cls, task_id, project_name, task_name, include_archived, tags, task_filter)\u001b[0m\n\u001b[1;32m   4123\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   4124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__get_task\u001b[39m(\n\u001b[1;32m   4125\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4132\u001b[0m ):\n\u001b[1;32m   4133\u001b[0m     \u001b[39m# type: (...) -> TaskInstance\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m     \u001b[39mif\u001b[39;00m task_id:\n\u001b[0;32m-> 4136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(private\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__create_protection, task_id\u001b[39m=\u001b[39;49mtask_id, log_to_backend\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   4138\u001b[0m     \u001b[39mif\u001b[39;00m project_name:\n\u001b[1;32m   4139\u001b[0m         res \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_send(\n\u001b[1;32m   4140\u001b[0m             \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_default_session(),\n\u001b[1;32m   4141\u001b[0m             projects\u001b[39m.\u001b[39mGetAllRequest(\n\u001b[1;32m   4142\u001b[0m                 name\u001b[39m=\u001b[39mexact_match_regex(project_name)\n\u001b[1;32m   4143\u001b[0m             )\n\u001b[1;32m   4144\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/clearml/lib/python3.10/site-packages/clearml/task.py:200\u001b[0m, in \u001b[0;36mTask.__init__\u001b[0;34m(self, private, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[39mraise\u001b[39;00m UsageError(\n\u001b[1;32m    197\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mTask object cannot be instantiated externally, use Task.current_task() or Task.get_task(...)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_repo_detect_lock \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mRLock()\n\u001b[0;32m--> 200\u001b[0m \u001b[39msuper\u001b[39;49m(Task, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_arguments \u001b[39m=\u001b[39m _Arguments(\u001b[39mself\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/clearml/lib/python3.10/site-packages/clearml/backend_interface/task/task.py:187\u001b[0m, in \u001b[0;36mTask.__init__\u001b[0;34m(self, session, task_id, log, project_name, task_name, task_type, log_to_backend, raise_on_validation_errors, force_create)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(check_output_dest_credentials\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTask ID \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m could not be found\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid))\n\u001b[1;32m    189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_project_name \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject, project_name)\n\u001b[1;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_project_object \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Task ID \"d\" could not be found"
     ]
    }
   ],
   "source": [
    "# Preprocessing code here\n",
    "dataset = Dataset.create(\n",
    "  dataset_name='sample_nlst_local',\n",
    "  dataset_project='mehdi_test_nlst/clml_dataset', \n",
    "  parent_datasets=[\"dff321121eb7463b8180e03e331c189d\"],\n",
    "  #dataset_version=\"1.0\",\n",
    "  #output_uri=\"gs://bucket-name/folder\",\n",
    "  description='csv added, small sample of nlst from local'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SHA2 hash for 640 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 640/640 [00:00<00:00, 1740.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash generation completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.add_files(\n",
    "  path=\"./data/nlst_sample\",\n",
    "  wildcard=\"*.dcm\",\n",
    "  recursive=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading dataset changes (640 files compressed to 302.28 MiB) to https://files.genentech.hosted.allegro.ai\n",
      "File compression and upload completed: total size 302.28 MiB, 1 chunk(s) stored (average size 302.28 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying (Retry(total=237, connect=237, read=240, redirect=240, status=240)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa3a80db670>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /v2.23/tasks.ping\n"
     ]
    }
   ],
   "source": [
    "dataset.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clearml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
